install.packages('rLakeAnalyzer')
install.packages('plyr')
install.packages('R2jags')
install.packages('R2WinBUGS')
library(R2jags)
install.packages('raster')
cite('raster')
library(raster)
cite(raster)
cite('raster')
citation('raster')
remove.packages('rLakeAnalyzer')
install.packages('rLakeAnalyzer')
library(rLakeAnalyzer)
?rLakeAnalyzer
?wrt.heat.map
?wtr.heat.map
Get the path for the package example file included
wtr.path <- system.file('extdata', 'Sparkling.daily.wtr', package="rLakeAnalyzer")
#Load data for example lake, Sparkilng Lake, Wisconsin.
sp.wtr = load.ts(wtr.path)
#Plot default figure
wtr.heat.map(sp.wtr)
#Change defaults supplied to filled.contour
wtr.heat.map(sp.wtr, zlim=c(0,15), plot.title="Sparkling Water Temp (C)")
Get the path for the package example file included
wtr.path <- system.file('extdata', 'Sparkling.daily.wtr', package="rLakeAnalyzer")
#Load data for example lake, Sparkilng Lake, Wisconsin.
sp.wtr = load.ts(wtr.path)
#Plot default figure
wtr.heat.map(sp.wtr)
#Change defaults supplied to filled.contour
wtr.heat.map(sp.wtr, zlim=c(0,15), plot.title="Sparkling Water Temp (C)")
wtr.heat.map(sp.wtr, zlim=c(0,15), plot.title="Sparkling Water Temp (C)")
wtr.heat.map(sp.wtr, zlim=c(0,25), plot.title="Sparkling Water Temp (C)")
rainbow(10)
colors = rainbow(ncol(sp.wtr))
wtr.path <- system.file('extdata', 'Sparkling.daily.wtr', package="rLakeAnalyzer")
library(rLakeAnalyzer)
wtr.path <- system.file('extdata', 'Sparkling.daily.wtr', package="rLakeAnalyzer")
sp.wtr = load.ts(wtr.path)
colors = rainbow(ncol(sp.wtr))
plot(sp.wtr[,1], sp.wtr[,1], type='l', col=colors[1])
plot(sp.wtr[,1], sp.wtr[,2], type='l', col=colors[1])
for i in 3:ncol(sp.wtr){
lines(sp.wtr[,1], sp.wtr[,i], type='l', col=colors[i]])
}
for i in 3:ncol(sp.wtr){
for( i in 3:ncol(sp.wtr)){
lines(sp.wtr[,1], sp.wtr[,i], type='l', col=colors[i]])
}
for( i in 3:ncol(sp.wtr)){
lines(sp.wtr[,1], sp.wtr[,i], type='l', col=colors[i]])
for( i in 3:ncol(sp.wtr)){
lines(sp.wtr[,1], sp.wtr[,i], type='l', col=colors[i])
}
wtr.path <- system.file('extdata', 'Sparkling.daily.wtr', package="rLakeAnalyzer")
wtr.path
update.packages
update.packages()
source('C:/Users/lawinslow/Desktop/colors.could.be.better.R', echo=TRUE)
217*.27
distance = seq(0,10,by=0.1)
source('D:/Dropbox/rLakeAnalyzer/rLakeAnalyzer/R/wtr.heatmap.layers.R', echo=TRUE)
prompt(wtr.heatmap.layers,'wtr.heatmap.layers.Rd')
getwd()
dates = seq(as.POSIXct('2010-01-01'), as.POSIXct('2011-01-01'), by='1 day')
dates
?Date
as.Date('2010-01-01')
as.Date('2010-01-01 10:00:00')
as.numeric(as.Date('2010-01-01'))
as.numeric(as.Date('2010-01-01'))/365
as.POSIXct('2010-01-01 10:00:00')
?POSIXct
as.numeric(as.POSIXct('2010-01-01 10:00:00'))
as.numeric(as.POSIXct('2010-01-01 10:00:00'))/365
as.numeric(as.POSIXct('2010-01-01 10:00:00'))/365/24/60
as.numeric(as.POSIXct('2010-01-01 10:00:00'))/365/24/60/60
?POSIXlt
as.POSIXlt('2010-01-01 10:00:00')
as.numeric(as.POSIXlt('2010-01-01 10:00:00'))
as.list(as.POSIXlt('2010-01-01 10:00:00'))
class(as.POSIXlt('2010-01-01 10:00:00')) = NULL
?class
class(as.POSIXlt('2010-01-01 10:00:00'))
class(list())
class(as.POSIXlt('2010-01-01 10:00:00')) = "list"
assign(as.POSIXlt('2010-01-01 10:00:00')) = "list"
?assign
as.POSIXlt('2010-01-01 10:00:00')
unclass(as.POSIXlt('2010-01-01 10:00:00'))
unclass(as.POSIXlt('2010-01-02 10:00:00'))
as.POSIXlt('2010-01-02 10:00:00')$year
as.POSIXlt('2010-06-01 10:00:00')$yday
as.POSIXlt('2010-06-01 10:00:00')$yday+1
as.POSIXlt('2010-01-01 10:00:00')$yday
dates = seq(as.POSIXct('2010-01-01'), as.POSIXct('2011-01-01'), by='1 day')
dates
?rnorm
test = data.frame(datetime=dates, blah=rnorm(length(dates)))
test
head(test)
ss = as.POSIXct('2010-06-21')
ss
test$datetime > ss
test$afterSS = test$datetime > ss
test$beforeSS = test$datetime < ss
head(test)
which(test$datetime > ss)
which(test$datetime < ss)
test$gasPrice = NA
head(test)
test = data.frame(datetime=dates, blah=rnorm(length(dates)))
ss = as.POSIXct('2010-06-21')
test$gasPrice = NA
head(test)
test[test$datetime > ss, ] = price.after.ss
test[test$datetime < ss, ] = price.before.ss
price.before.ss = 3.00
price.after.ss  = 4.00
test[test$datetime > ss, ] = price.after.ss
test[test$datetime < ss, ] = price.before.ss
testss
ss
test$gasPrice[test$datetime > ss] = price.after.ss
test$gasPrice[test$datetime < ss] = price.before.ss
test
plot(test$datetime, plot$gasPrice)
plot(test$datetime, test$gasPrice)
plot(test$datetime, test$gasPrice, xlim=c(0,5))
plot(test$datetime, test$gasPrice, ylim=c(0,5))
citation(rLakeAnalyzer)
citation('rLakeAnalyzer')
library(LakeMetabolizer)
library(data.table)
library(plyr)
data.path = 'D:/Dropbox/Work/Clean Buoy Data/Mendota'
doobs = load.ts(file.path(data.path, '2009','Mendota.doobs'))
wnd = load.ts(file.path(data.path, '2009','Mendota.wnd'))
wtr = load.ts(file.path(data.path, '2009','Mendota.wtr'))
par = load.ts(file.path(data.path, '2009','Mendota.par'))
#Scale wind to U10
U10 = wind.scale(wnd,2)
# Calculate z.mix
md = ts.meta.depths(wtr, seasonal=TRUE)
z.mix = md[,1:2]
names(z.mix)[2] = 'z.mix'
# Calculate DO - DOSat
dosat = o2.at.sat(wtr[,c('datetime', 'wtr_0')], altitude=260)
both = merge(dosat, doobs)
both$deltaSat = both$do - both$do.sat
deltaSat = both[,c('datetime','deltaSat')]
# Calculate dDO and dT
dDO = data.frame(datetime = doobs$datetime[1:(nrow(doobs)-1)],
dDO = diff(doobs$do))
#strip any attributes, make sure dt is in units of minutes
dt = data.frame(datetime = doobs$datetime[1:(nrow(doobs)-1)],
dt = as.numeric(diff(doobs$datetime, units="mins")))
all.data = merge(merge(merge(merge(merge(merge(dt,dDO), deltaSat), par), U10), wtr[,c('datetime', 'wtr_0')]), z.mix)
all.data = data.table(all.data[complete.cases(all.data),])
all.data = all.data[dt==1 & z.mix > 0,] #use only 1 minute data
cuts = c(0, 1, 3, 5, 10, 20, 100)
#  Parameters: do offset, then k600 (m/day) for each wind bin
start.par = c(0, rep(4,length(cuts)-1))
parameters = start.par
do.offset = params[1]
params = start.par
do.offset = params[1]
vals = params[2:length(params)]
k600 = vals[cut(all.data$wnd_10, cuts, right=FALSE)]
k.gas = k600.2.kGAS.base(k600, all.data$wtr_0, gas='O2')
inst_flux <- (k.gas*(all.data$dt/1440) * (all.data$deltaSat + do.offset)*-1) #(do.sat - do.obs)
all.data$noflux.do.diff <- all.data$dDO - inst_flux/all.data$z.mix
all.data[,day:=as.POSIXct(trunc(datetime, units='days'))]
tmp = ddply(all.data, 'day', function(df){sum(resid(lm(df$noflux.do.diff ~ df$par - 1))^2)})
tmp
tmp$V1
sum(tmp$V1)
(sum(resid(mod)^2))
mod <- lm(noflux.do.diff ~ all.data$par - 1)
mod <- lm(all.data$noflux.do.diff ~ all.data$par - 1)
(sum(resid(mod)^2))
sse = sum(tmp$V1)
sse
?optim
sqrt(0.09)
(0.09)^2
?globalVariables
library(devtools)
install_github(repo='EML','ropensci')
install.packages('RWordXML')
install_github(repo='RWordXML','duncantl')
install.packages('Rcompression')
install.packages('Rcompression', repos = "http://www.omegahat.org/R")
install.packages('Rcompression', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R")
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
install.packages('ROOXML', repos = "http://www.omegahat.org/R", type='source')
citation
citation(rLakeAnalyzer)
library(rLakeAnalyzer)
citation(rLakeAnalyzer)
citation('rLakeAnalyzer')
citation('LakeMetabolizer')
library(RCurl)
library(XML)
setwd("C:/Users/lawinslow/Desktop/ca_reservoirs/R")
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
scrape_ca_storage = function(site){
theurl = sprintf('http://cdec.water.ca.gov/cgi-progs/queryDaily?%s&d=%s&span=2000days',
site, '14-Sep-2014')
cat(theurl,'\n')
tables = readHTMLTable(theurl)
## it seems to be the only table grabbed. We must be lucky
data = tables[[1]]
data = data[,c('Date', 'STORAGE&nbsp')]
#2nd row are units. Drop them
data = data[-1,]
names(data) = c("Date", "Storage(acre-feet)")
data$Date = strptime(data$Date, '%m/%d/%Y')
data$`Storage(acre-feet)` = as.numeric(as.character(data[,2]))
return(data)
}
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
Sys.glob('../storage_data/*')
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
i=1
fname = paste0('../storage_data/', sites$ID[i], '.csv')
if(!file.exists(fname)){
next
}
read.csv(fname, as.is=TRUE)
data = read.csv(fname, as.is=TRUE)
nrow(data)
all.data = data.frame()
head(data)
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
all.data = data.frame()
for(i in 1:nrow(sites)){
fname = paste0('../storage_data/', sites$ID[i], '.csv')
if(!file.exists(fname)){
next
}
data = read.csv(fname, as.is=TRUE)
if(nrow(data < 1500)){
next
}
names(data) = c("Date", sites$ID[i])
all.data = merge(all.data, data, by="Date")
}
head(all.data)
if(nrow(data < 1500)){
debugSource('C:/Users/lawinslow/Desktop/ca_reservoirs/R/figure_all_combined_reservoirs.R', echo=TRUE)
data
all.data
all.data
head(all.data)
?merge
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
all.data = data.frame()
for(i in 1:nrow(sites)){
fname = paste0('../storage_data/', sites$ID[i], '.csv')
if(!file.exists(fname)){
next
}
data = read.csv(fname, as.is=TRUE)
if(nrow(data < 1500)){
next
}
names(data) = c("Date", sites$ID[i])
all.data = merge(all.data, data, by="Date", all=TRUE)
}
head(all.data)
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
all.data = data.frame()
for(i in 1:nrow(sites)){
fname = paste0('../storage_data/', sites$ID[i], '.csv')
if(!file.exists(fname)){
next
}
data = read.csv(fname, as.is=TRUE)
if(nrow(data < 1500)){
next
}
names(data) = c("Date", sites$ID[i])
if(nrow(all.data) == 0){
all.data = data
}else{
all.data = merge(all.data, data, by="Date", all=TRUE)
}
}
all.data
head(all.data)
nrow(all.data)
i=1
fname = paste0('../storage_data/', sites$ID[i], '.csv')
if(!file.exists(fname)){
next
}
data = read.csv(fname, as.is=TRUE)
data
merge(all.data,data)
if(nrow(data < 1500)){
next
}
sites = read.csv('../Data/ca_reservoirs.csv', as.is=TRUE)
all.data = data.frame()
for(i in 1:nrow(sites)){
fname = paste0('../storage_data/', sites$ID[i], '.csv')
if(!file.exists(fname)){
next
}
data = read.csv(fname, as.is=TRUE)
if(nrow(data) < 1500){
next
}
names(data) = c("Date", sites$ID[i])
if(nrow(all.data) == 0){
all.data = data
}else{
all.data = merge(all.data, data, by="Date", all=TRUE)
}
}
all.data
head(all.data)
all.data$PRR
all.data[complete.cases(all.data),]
complete.cases(all.data)
lapply(all.data, is.na)
as.matrix(all.data[,-1])
apply(as.matrix(all.data[,-1]), 1, sum)
apply(as.matrix(all.data[,-1]), 1, sum, na.rm=TRUE
)
apply(as.matrix(all.data[,-1]), 1, sum, na.rm=TRUE)
all.dates = all.data$Date
all.vols = apply(as.matrix(all.data[,-1]), 1, sum, na.rm=TRUE)
plot(all.dates, all.vols)
all.dates
all.dates = as.POSIXct(all.data$Date)
all.vols = apply(as.matrix(all.data[,-1]), 1, sum, na.rm=TRUE)
plot(all.dates, all.vols)
plot(all.dates, all.vols, ylim=c0, 3e7)
all.vols
length(all.dates)
plot(all.dates, all.vols, ylim=c(0, 3e7))
plot(all.dates, all.vols/810713.194, ylim=c(0, 3e7))
plot(all.dates, all.vols/810713.194)
plot(all.dates, all.vols/810713.194, ylim=c(0,40))
plot(all.dates, all.vols/810713.194, ylim=c(0,38))
plot(all.dates, all.vols/810713.194, ylim=c(0,38), ylab=equation(Storage~km^3))
plot(all.dates, all.vols/810713.194, ylim=c(0,38), ylab=expression(Storage~km^3))
plot(all.dates, all.vols/810713.194, ylim=c(0,38), ylab=expression(Storage~km^3), xlab='')
png('figure_all_CA_storage.png')
plot(all.dates, all.vols/810713.194, ylim=c(0,38), ylab=expression(Storage~km^3), xlab='')
dev.off()
png('figure_all_CA_storage.png', width=1200, height=900, res=300)
plot(all.dates, all.vols/810713.194, ylim=c(0,38), ylab=expression(Storage~km^3), xlab='')
dev.off()
plot(all.dates, all.vols/810713.194, ylim=c(15,38), ylab=expression(Storage~km^3), xlab='')
plot(all.dates, all.vols/810713.194, ylim=c(12,38), ylab=expression(Storage~km^3), xlab='')
png('figure_all_CA_storage.png', width=1200, height=900, res=300)
plot(all.dates, all.vols/810713.194, ylim=c(12,38), ylab=expression(Storage~km^3), xlab='')
dev.off()
png('figure_all_CA_storage.png', width=1200, height=900, res=150)
plot(all.dates, all.vols/810713.194, ylim=c(12,38), ylab=expression(Storage~km^3), xlab='')
dev.off()
png('../storage_plots/figure_all_CA_storage.png', width=1200, height=900, res=150)
plot(all.dates, all.vols/810713.194, ylim=c(12,38), ylab=expression(Storage~km^3), xlab='')
dev.off()
